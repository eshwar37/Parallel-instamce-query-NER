{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617fcedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import torch\n",
    "from torch.nn import DataParallel\n",
    "from torch.nn.parallel.distributed import DistributedDataParallel\n",
    "from torch.optim import Optimizer\n",
    "from transformers import PreTrainedModel\n",
    "from transformers import PreTrainedTokenizer\n",
    "\n",
    "from piqn import util\n",
    "import torch.utils.tensorboard as tensorboard\n",
    "\n",
    "SCRIPT_PATH = os.path.dirname(os.path.realpath(__file__))\n",
    "\n",
    "\n",
    "class BaseTrainer:\n",
    "    \"\"\" Trainer base class with common methods \"\"\"\n",
    "\n",
    "    def __init__(self, args: argparse.Namespace):\n",
    "        self.args = args\n",
    "        self._debug = self.args.debug\n",
    "\n",
    "        self.local_rank = args.local_rank\n",
    "        self.record = False\n",
    "        if self.local_rank < 1:\n",
    "            self.record = True\n",
    "\n",
    "        # logging\n",
    "        name = str(datetime.datetime.now()).replace(' ', '_')\n",
    "        self._log_path = os.path.join(self.args.log_path, self.args.label, name)\n",
    "        if self.record:\n",
    "            util.create_directories_dir(self._log_path)\n",
    "\n",
    "        if hasattr(args, 'save_path') and self.record:\n",
    "            self._save_path = os.path.join(self.args.save_path, self.args.label, name)\n",
    "            util.create_directories_dir(self._save_path)\n",
    "\n",
    "        self._log_paths = dict()\n",
    "\n",
    "        # file + console logging\n",
    "        log_formatter = logging.Formatter(\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\")\n",
    "        self._logger = logging.getLogger()\n",
    "        util.reset_logger(self._logger)\n",
    "\n",
    "        if self.record:\n",
    "            file_handler = logging.FileHandler(os.path.join(self._log_path, 'all.log'))\n",
    "            file_handler.setFormatter(log_formatter)\n",
    "            self._logger.addHandler(file_handler)\n",
    "\n",
    "        console_handler = logging.StreamHandler(sys.stdout)\n",
    "        console_handler.setFormatter(log_formatter)\n",
    "        if \"pretrain\" not in self.args.label:\n",
    "            self._logger.addHandler(console_handler)\n",
    "\n",
    "        if self._debug:\n",
    "            self._logger.setLevel(logging.DEBUG)\n",
    "        else:\n",
    "            self._logger.setLevel(logging.INFO)\n",
    "\n",
    "        # tensorboard summary\n",
    "        if self.record:\n",
    "            self._summary_writer = tensorboard.SummaryWriter(self._log_path)\n",
    "\n",
    "        self._best_results = dict()\n",
    "        if self.record:\n",
    "            self._log_arguments()\n",
    "\n",
    "        # CUDA devices\n",
    "        # self._device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.cpu else \"cpu\")\n",
    "        if args.cpu:\n",
    "            device=\"cpu\"\n",
    "        else:\n",
    "            device=\"cuda:\" + str(args.device_id)\n",
    "\n",
    "\n",
    "        # set seed\n",
    "        if args.seed is not None:\n",
    "            util.set_seed(args.seed)\n",
    "\n",
    "        if args.local_rank != -1 and \"eval\"  not in args.label:\n",
    "            torch.cuda.set_device(args.local_rank)\n",
    "            torch.distributed.init_process_group(backend='nccl', init_method='env://', rank = args.local_rank, world_size = args.world_size)\n",
    "            self._device = torch.device('cuda', args.local_rank)\n",
    "        else:\n",
    "            self._device = torch.device(device)\n",
    "            self._gpu_count = torch.cuda.device_count()\n",
    "\n",
    "    def _add_dataset_logging(self, *labels, data: Dict[str, List[str]]):\n",
    "        for label in labels:\n",
    "            dic = dict()\n",
    "\n",
    "            for key, columns in data.items():\n",
    "                path = os.path.join(self._log_path, '%s_%s.csv' % (key, label))\n",
    "                util.create_csv(path, *columns)\n",
    "                dic[key] = path\n",
    "\n",
    "            self._log_paths[label] = dic\n",
    "            self._best_results[label] = 0\n",
    "\n",
    "    def _log_arguments(self):\n",
    "        util.save_dict(self._log_path, self.args, 'args')\n",
    "        if self._summary_writer is not None:\n",
    "            util.summarize_dict(self._summary_writer, self.args, 'args')\n",
    "\n",
    "    def _log_tensorboard(self, dataset_label: str, data_label: str, data: object, iteration: int):\n",
    "        if self._summary_writer is not None:\n",
    "            self._summary_writer.add_scalar('data/%s/%s' % (dataset_label, data_label), data, iteration)\n",
    "\n",
    "    def _log_csv(self, dataset_label: str, data_label: str, *data: Tuple[object]):\n",
    "        logs = self._log_paths[dataset_label]\n",
    "        util.append_csv(logs[data_label], *data)\n",
    "\n",
    "    # def _save_best(self, model: PreTrainedModel, tokenizer: PreTrainedTokenizer, optimizer: Optimizer,\n",
    "    #                accuracy: float, iteration: int, label: str, extra=None):\n",
    "    #     if accuracy > self._best_results[label]:\n",
    "    #         self._logger.info(\"[%s] Best model in iteration %s: %s%% accuracy\" % (label, iteration, accuracy))\n",
    "    #         self._save_model(self._save_path, model, tokenizer, iteration,\n",
    "    #                          optimizer=optimizer if self.args.save_optimizer else None,\n",
    "    #                          save_as_best=True, name='model_%s' % label, extra=extra)\n",
    "    #         self._best_results[label] = accuracy\n",
    "\n",
    "    def _save_model(self, save_path: str, model: PreTrainedModel, tokenizer: PreTrainedTokenizer,\n",
    "                    iteration: int, optimizer: Optimizer = None, save_as_best: bool = False,\n",
    "                    extra: dict = None, include_iteration: int = True, name: str = 'model'):\n",
    "        extra_state = dict(iteration=iteration)\n",
    "\n",
    "        if optimizer:\n",
    "            extra_state['optimizer'] = optimizer.state_dict()\n",
    "\n",
    "        if extra:\n",
    "            extra_state.update(extra)\n",
    "\n",
    "        if save_as_best:\n",
    "            dir_path = os.path.join(save_path, 'best_%s' % name)\n",
    "        else:\n",
    "            dir_name = '%s_%s' % (name, iteration) if include_iteration else name\n",
    "            dir_path = os.path.join(save_path, dir_name)\n",
    "\n",
    "        util.create_directories_dir(dir_path)\n",
    "\n",
    "        # save model\n",
    "        if isinstance(model, (DataParallel, DistributedDataParallel)):\n",
    "            model.module.save_pretrained(dir_path)\n",
    "        else:\n",
    "            model.save_pretrained(dir_path)\n",
    "\n",
    "        # save vocabulary\n",
    "        tokenizer.save_pretrained(dir_path)\n",
    "\n",
    "        # save extra\n",
    "        state_path = os.path.join(dir_path, 'extra.state')\n",
    "        torch.save(extra_state, state_path)\n",
    "\n",
    "    def _get_lr(self, optimizer):\n",
    "        lrs = []\n",
    "        for group in optimizer.param_groups:\n",
    "            lr_scheduled = group['lr']\n",
    "            lrs.append(lr_scheduled)\n",
    "        return lrs\n",
    "\n",
    "    def _close_summary_writer(self):\n",
    "        if self._summary_writer is not None:\n",
    "            self._summary_writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2805545f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
